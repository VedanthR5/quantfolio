{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45db9e43",
   "metadata": {},
   "source": [
    "# ARIMA Time Series Forecasting for Stock Prices\n",
    "\n",
    "**A Step-by-Step Guide to Predicting AAPL Stock Prices**\n",
    "\n",
    "---\n",
    "\n",
    "## What is ARIMA?\n",
    "\n",
    "**ARIMA (AutoRegressive Integrated Moving Average)** is a popular statistical model for time series forecasting. It combines three components:\n",
    "\n",
    "- **AR (AutoRegressive)**: Uses past values to predict future values\n",
    "- **I (Integrated)**: Differencing to make non-stationary data stationary\n",
    "- **MA (Moving Average)**: Uses past forecast errors in the prediction\n",
    "\n",
    "### ARIMA Parameters (p, d, q)\n",
    "\n",
    "| Parameter | Description | How to Choose |\n",
    "|-----------|-------------|---------------|\n",
    "| **p** | Number of lag observations (AR terms) | Use PACF plot |\n",
    "| **d** | Degree of differencing | Use ADF test |\n",
    "| **q** | Size of moving average window | Use ACF plot |\n",
    "\n",
    "### Why Use ARIMA for Stock Prices?\n",
    "\n",
    "1. Stock prices exhibit **trends** (non-stationary behavior)\n",
    "2. ARIMA can handle trends through differencing\n",
    "3. Walk-forward validation simulates real trading scenarios\n",
    "4. Provides interpretable forecasts\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Vedanth Ramanathan\n",
    "**Repository:** [vr-quantfolio-intro](https://github.com/vedanthr5/vr-quantfolio-intro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16795c0f",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eff2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation and numerical computing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Financial data\n",
    "import yfinance as yf\n",
    "\n",
    "# Statistical tests and models\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Machine learning metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All dependencies imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35e9c70",
   "metadata": {},
   "source": [
    "## 2. Load Stock Data\n",
    "\n",
    "We'll download AAPL (Apple Inc.) stock data from Yahoo Finance spanning from 2010 to 2025. This gives us approximately 15 years of daily trading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4040090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stock parameters\n",
    "stock = \"AAPL\"\n",
    "start_date = \"2010-12-20\"\n",
    "end_date = \"2025-12-30\"\n",
    "\n",
    "# Download stock data from Yahoo Finance\n",
    "# auto_adjust=False keeps original OHLC prices (not adjusted for splits/dividends)\n",
    "# multi_level_index=False gives us simple column names\n",
    "df = yf.download(\n",
    "    stock, \n",
    "    start=start_date, \n",
    "    end=end_date, \n",
    "    auto_adjust=False, \n",
    "    multi_level_index=False\n",
    ")\n",
    "\n",
    "# Check for and remove any missing values\n",
    "print(f\"Missing values: {df.isnull().values.any()}\")\n",
    "df = df.dropna()\n",
    "\n",
    "# Display basic info\n",
    "print(f\"\\n{stock} Stock Data Summary:\")\n",
    "print(f\"   Date Range: {df.index.min().date()} to {df.index.max().date()}\")\n",
    "print(f\"   Trading Days: {len(df):,}\")\n",
    "print(f\"   Columns: {list(df.columns)}\")\n",
    "\n",
    "# Show first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c58442",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's visualize the stock price to understand its behavior over time. We'll focus on the **Close** price, which is what we'll be forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd5a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive price chart with Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df.index, \n",
    "    y=df['Close'],\n",
    "    mode='lines',\n",
    "    name='Close Price',\n",
    "    line=dict(color='#2196F3', width=1.5)\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'{stock} Stock Price History',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Price (USD)',\n",
    "    template='plotly_white',\n",
    "    height=500,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a86d72",
   "metadata": {},
   "source": [
    "## 4. Train/Test Split\n",
    "\n",
    "For time series data, we **cannot** use random splits because the order of observations matters. We split chronologically:\n",
    "- **Training Set (80%)**: Historical data the model learns from\n",
    "- **Test Set (20%)**: Recent data to evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b73e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data: 80% training, 20% testing\n",
    "train_size = int(len(df) * 0.8)\n",
    "\n",
    "train = df['Close'][:train_size]\n",
    "test = df['Close'][train_size:]\n",
    "\n",
    "print(f\"Training Set: {len(train):,} observations\")\n",
    "print(f\"   From: {train.index.min().date()} to {train.index.max().date()}\")\n",
    "print(f\"\\nTest Set: {len(test):,} observations\")\n",
    "print(f\"   From: {test.index.min().date()} to {test.index.max().date()}\")\n",
    "\n",
    "# Visualize the split\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=train.index, y=train.values,\n",
    "    mode='lines', name='Training Data',\n",
    "    line=dict(color='#4CAF50', width=1.5)\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=test.index, y=test.values,\n",
    "    mode='lines', name='Test Data',\n",
    "    line=dict(color='#FF5722', width=1.5)\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Train/Test Split Visualization',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Close Price (USD)',\n",
    "    template='plotly_white',\n",
    "    height=450\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846ff552",
   "metadata": {},
   "source": [
    "## 5. Testing for Stationarity\n",
    "\n",
    "ARIMA requires **stationary** data, meaning:\n",
    "- Constant mean over time\n",
    "- Constant variance over time\n",
    "- No seasonal patterns\n",
    "\n",
    "We use the **Augmented Dickey-Fuller (ADF) Test**:\n",
    "- **H₀ (Null)**: The series has a unit root (non-stationary)\n",
    "- **H₁ (Alternative)**: The series is stationary\n",
    "\n",
    "If **p-value < 0.05**, we reject H₀ and conclude the series is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e042bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform ADF test and display results\n",
    "def adf_test(series, title=''):\n",
    "    \"\"\"\n",
    "    Perform Augmented Dickey-Fuller test for stationarity.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if stationary (p < 0.05), False otherwise\n",
    "    \"\"\"\n",
    "    result = adfuller(series.dropna())\n",
    "    \n",
    "    print(f\"ADF Test Results {title}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"   Test Statistic: {result[0]:.4f}\")\n",
    "    print(f\"   P-Value: {result[1]:.6f}\")\n",
    "    print(f\"   Lags Used: {result[2]}\")\n",
    "    print(f\"   Observations: {result[3]}\")\n",
    "    print(\"\\n   Critical Values:\")\n",
    "    for key, value in result[4].items():\n",
    "        print(f\"      {key}: {value:.4f}\")\n",
    "    \n",
    "    is_stationary = result[1] < 0.05\n",
    "    print(f\"\\n   Conclusion: {'STATIONARY' if is_stationary else 'NON-STATIONARY'}\")\n",
    "    \n",
    "    return is_stationary\n",
    "\n",
    "# Test original price series\n",
    "print(\"Testing ORIGINAL Close Prices:\\n\")\n",
    "is_original_stationary = adf_test(train, title='(Original Prices)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2804d4c",
   "metadata": {},
   "source": [
    "## 6. Differencing: Making Data Stationary\n",
    "\n",
    "Since stock prices are non-stationary (they trend upward/downward), we apply **differencing**:\n",
    "\n",
    "$$X'_t = X_t - X_{t-1}$$\n",
    "\n",
    "This transforms prices into **daily changes**, which fluctuate around zero and are typically stationary.\n",
    "\n",
    "**Why this works:**\n",
    "- Original: `[100, 102, 105, 103, 108]` → Trending up\n",
    "- Differenced: `[+2, +3, -2, +5]` → Fluctuates around zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de61e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply differencing to training data\n",
    "# diff() computes: current_value - previous_value\n",
    "train_diff = train.diff().dropna()\n",
    "\n",
    "# Visualize before and after differencing\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Original prices\n",
    "axes[0].plot(train.index, train.values, color='#2196F3', linewidth=1)\n",
    "axes[0].set_title('Original Prices (Non-Stationary)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Price (USD)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Differenced prices\n",
    "axes[1].plot(train_diff.index, train_diff.values, color='#4CAF50', linewidth=0.8)\n",
    "axes[1].axhline(y=0, color='red', linestyle='--', alpha=0.7, label='Zero Line')\n",
    "axes[1].set_title('Differenced Prices (Stationary)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Daily Change (USD)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test if differenced series is stationary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Testing DIFFERENCED Close Prices:\\n\")\n",
    "is_diff_stationary = adf_test(train_diff, title='(Differenced Prices)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4621212",
   "metadata": {},
   "source": [
    "## 7. ARIMA Model Training\n",
    "\n",
    "Now we'll train an ARIMA model with:\n",
    "- **p = 1**: One autoregressive term (uses 1 past value)\n",
    "- **d = 2**: Two levels of differencing (ARIMA applies its own differencing)\n",
    "- **q = 1**: One moving average term\n",
    "\n",
    "### Walk-Forward Validation\n",
    "\n",
    "Instead of training once and predicting all test data, we use **walk-forward validation**:\n",
    "1. Train on all available historical data\n",
    "2. Predict the next day\n",
    "3. Add that actual value to training set\n",
    "4. Retrain and repeat\n",
    "\n",
    "This mimics real-world trading where you retrain models as new data arrives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c883f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for walk-forward validation\n",
    "# history: growing list of training observations (starts with full train set)\n",
    "history = train.tolist()\n",
    "\n",
    "# predictions: will store our model's forecasts for each test observation\n",
    "predictions = []\n",
    "\n",
    "# ARIMA parameters\n",
    "order = (1, 2, 1)  # (p, d, q)\n",
    "\n",
    "print(f\"Starting Walk-Forward ARIMA Training\")\n",
    "print(f\"   Order: {order}\")\n",
    "print(f\"   Test observations to predict: {len(test)}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Walk-forward validation loop\n",
    "# For each day in test set: train model, predict, add actual, repeat\n",
    "for t in range(len(test)):\n",
    "    # Train ARIMA model on all historical data available so far\n",
    "    model = ARIMA(history, order=order)\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    # Forecast the next day's price\n",
    "    # forecast() returns an array, we take the first (only) element\n",
    "    yhat = model_fit.forecast()[0]\n",
    "    predictions.append(yhat)\n",
    "    \n",
    "    # Add the ACTUAL observed value to history for next iteration\n",
    "    # This is key: we're NOT adding our prediction, but the real value\n",
    "    actual = test.iloc[t]\n",
    "    history.append(actual)\n",
    "    \n",
    "    # Progress update every 100 iterations\n",
    "    if (t + 1) % 100 == 0 or t == 0:\n",
    "        print(f\"   Completed {t + 1}/{len(test)} predictions\")\n",
    "\n",
    "print(f\"\\nTraining complete. Generated {len(predictions)} predictions.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22e94db",
   "metadata": {},
   "source": [
    "## 8. Understanding the Cumulative Sum Reversal\n",
    "\n",
    "⚠️ **Critical Concept**: ARIMA with `d=2` works on **twice-differenced data**. Its predictions are in \"change-of-changes\" space, NOT actual prices!\n",
    "\n",
    "### The Problem\n",
    "- Raw ARIMA predictions: Changes in changes (meaningless for trading)\n",
    "- What we need: Actual price predictions\n",
    "\n",
    "### The Solution: Cumulative Sum (cumsum)\n",
    "\n",
    "Since differencing = subtraction, the inverse is **cumulative sum** (adding up).\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Original prices:     [100, 102, 105, 103, 108]\n",
    "1st diff (changes):  [+2, +3, -2, +5]\n",
    "2nd diff (Δchanges): [+1, -5, +7]\n",
    "\n",
    "To reverse:\n",
    "cumsum([+1, -5, +7]) → [+1, -4, +3] ≈ 1st diff\n",
    "cumsum([+2, +1, -4, +3]) → [2, 3, -1, 2] ... needs anchor!\n",
    "```\n",
    "\n",
    "We anchor the cumsum at the **last known training price** to get actual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbcb68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 1: Apply differencing to test data (for comparison)\n",
    "# ============================================================\n",
    "# We difference test data to get \"changes\" which ARIMA predicts\n",
    "test_diff = test.diff().dropna()\n",
    "\n",
    "# ============================================================\n",
    "# STEP 2: Convert predictions to pandas Series with proper index\n",
    "# ============================================================\n",
    "# predictions list -> Series aligned with test dates\n",
    "predictions_series = pd.Series(predictions, index=test.index)\n",
    "\n",
    "# Difference the predictions too (since ARIMA predicts d=2 space)\n",
    "predictions_diff = predictions_series.diff().dropna()\n",
    "\n",
    "# ============================================================\n",
    "# STEP 3: Cumulative sum reversal - THE KEY STEP\n",
    "# ============================================================\n",
    "# cumsum() reverses differencing by accumulating the changes\n",
    "# But we need an anchor point - the last known price before test period\n",
    "\n",
    "# Get the anchor: last training price\n",
    "anchor_price = train.iloc[-1]\n",
    "print(f\"Anchor price (last training value): ${anchor_price:.2f}\")\n",
    "\n",
    "# Reverse the differencing for ACTUAL test values\n",
    "# cumsum() accumulates: [a, b, c] -> [a, a+b, a+b+c]\n",
    "# Adding anchor shifts the whole series to correct price level\n",
    "reverse_test_diff = test_diff.cumsum() + anchor_price\n",
    "\n",
    "# Reverse the differencing for PREDICTED values\n",
    "reverse_predictions = predictions_diff.cumsum() + anchor_price\n",
    "\n",
    "print(f\"\\nReversed {len(reverse_predictions)} predictions back to price space.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec76071",
   "metadata": {},
   "source": [
    "## 9. Error Calculation\n",
    "\n",
    "We evaluate model performance using two metrics:\n",
    "\n",
    "### Mean Squared Error (MSE)\n",
    "$$MSE = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2$$\n",
    "- Penalizes large errors heavily (squared)\n",
    "- Lower is better\n",
    "\n",
    "### Symmetric Mean Absolute Percentage Error (SMAPE)\n",
    "$$SMAPE = \\frac{100\\%}{n}\\sum_{i=1}^{n}\\frac{|y_i - \\hat{y}_i|}{(|y_i| + |\\hat{y}_i|)/2}$$\n",
    "- Scale-independent (percentage)\n",
    "- Ranges from 0% (perfect) to 200% (terrible)\n",
    "- Symmetric: treats over/under-prediction equally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c233b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FINAL STEP: Calculate prediction error metrics\n",
    "# ============================================================\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Align the series (they should match but let's be safe)\n",
    "# Use intersection of indices\n",
    "common_index = reverse_test_diff.index.intersection(reverse_predictions.index)\n",
    "actual = reverse_test_diff.loc[common_index]\n",
    "predicted = reverse_predictions.loc[common_index]\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(actual, predicted)\n",
    "rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "\n",
    "print(\"Prediction Error Metrics\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Mean Absolute Error (MAE):     ${mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): ${rmse:.2f}\")\n",
    "print(f\"Mean Absolute % Error (MAPE):  {mape:.2f}%\")\n",
    "\n",
    "print(\"\\nInterpretation\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"On average, predictions were off by ${mae:.2f}\")\n",
    "print(f\"This represents a {mape:.1f}% error rate\")\n",
    "\n",
    "if mape < 5:\n",
    "    print(\"Result: Excellent accuracy for stock prediction.\")\n",
    "elif mape < 10:\n",
    "    print(\"Result: Good accuracy, usable for trend analysis.\")\n",
    "else:\n",
    "    print(\"Result: Moderate accuracy - use with caution.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72edc63d",
   "metadata": {},
   "source": [
    "## 10. Final Visualization: Predictions vs Actual\n",
    "\n",
    "Let's visualize how well our ARIMA model performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad54ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=(\n",
    "        'Full Price History with Predictions',\n",
    "        'Test Period: Actual vs Predicted',\n",
    "        'Prediction Errors Over Time',\n",
    "        'Error Distribution'\n",
    "    ),\n",
    "    vertical_spacing=0.12,\n",
    "    horizontal_spacing=0.1\n",
    ")\n",
    "\n",
    "# ---- Plot 1: Full history ----\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=train.index, y=train.values, name='Training Data',\n",
    "               line=dict(color='#2196F3', width=1)),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=actual_prices.index, y=actual_prices.values, name='Actual (Test)',\n",
    "               line=dict(color='#4CAF50', width=1.5)),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=predicted_prices.index, y=predicted_prices.values, name='Predicted',\n",
    "               line=dict(color='#FF5722', width=1.5, dash='dash')),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# ---- Plot 2: Zoomed test period ----\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=actual_prices.index, y=actual_prices.values, name='Actual',\n",
    "               line=dict(color='#4CAF50', width=2), showlegend=False),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=predicted_prices.index, y=predicted_prices.values, name='Predicted',\n",
    "               line=dict(color='#FF5722', width=2, dash='dash'), showlegend=False),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# ---- Plot 3: Errors over time ----\n",
    "errors = actual_prices - predicted_prices\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=errors.index, y=errors.values, name='Error',\n",
    "               line=dict(color='#9C27B0', width=1), showlegend=False),\n",
    "    row=2, col=1\n",
    ")\n",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"red\", row=2, col=1)\n",
    "\n",
    "# ---- Plot 4: Error distribution ----\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=errors.values, nbinsx=50, name='Error Distribution',\n",
    "                 marker_color='#9C27B0', showlegend=False),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    title_text=f'ARIMA({order[0]},{order[1]},{order[2]}) Model Performance on {stock}',\n",
    "    template='plotly_white',\n",
    "    showlegend=True,\n",
    "    legend=dict(x=0.02, y=0.98)\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text='Date', row=1, col=1)\n",
    "fig.update_xaxes(title_text='Date', row=1, col=2)\n",
    "fig.update_xaxes(title_text='Date', row=2, col=1)\n",
    "fig.update_xaxes(title_text='Error ($)', row=2, col=2)\n",
    "\n",
    "fig.update_yaxes(title_text='Price ($)', row=1, col=1)\n",
    "fig.update_yaxes(title_text='Price ($)', row=1, col=2)\n",
    "fig.update_yaxes(title_text='Error ($)', row=2, col=1)\n",
    "fig.update_yaxes(title_text='Count', row=2, col=2)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c90e9d",
   "metadata": {},
   "source": [
    "## 11. Key Takeaways\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Stationarity is Essential**: ARIMA requires stationary data. Stock prices are non-stationary, so we use differencing.\n",
    "\n",
    "2. **The ARIMA Process**:\n",
    "   - `p` (AR): How many past values influence the current value\n",
    "   - `d` (I): How many times to difference the data\n",
    "   - `q` (MA): How many past forecast errors influence the current forecast\n",
    "\n",
    "3. **Walk-Forward Validation**: More realistic than train-once-predict-all because it mimics real trading conditions.\n",
    "\n",
    "4. **Cumulative Sum Reversal**: Essential to convert ARIMA's difference-space predictions back to actual prices.\n",
    "\n",
    "5. **Model Limitations**: \n",
    "   - ARIMA assumes linear relationships\n",
    "   - Can't capture complex patterns or external factors\n",
    "   - Stock prices are notoriously hard to predict!\n",
    "\n",
    "### Next Steps:\n",
    "- Try different (p, d, q) parameters\n",
    "- Use `auto_arima` from `pmdarima` for automatic parameter selection\n",
    "- Explore SARIMA for seasonal data\n",
    "- Compare with machine learning approaches (LSTM, Prophet)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
